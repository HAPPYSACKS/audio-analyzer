<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>iPhone Lock Screen Mimic for iPhone 11</title>
    <link rel="stylesheet" href="style.css" />
  </head>
  <body>
    <div class="lock-screen">
      <div class="time">11:39</div>
      <div class="date">Monday, September 12</div>
      <div class="prompt" id="randomPrompt"></div>
      <button id="recordButton">Start Recording</button>
      <!-- <svg
        id="mic"
        fill="#ffffff"
        height="200px"
        width="200px"
        version="1.1"
        xmlns="http://www.w3.org/2000/svg"
        viewBox="0 0 512 512"
        xmlns:xlink="http://www.w3.org/1999/xlink"
        enable-background="new 0 0 512 512"
      >
        <g id="SVGRepo_bgCarrier" stroke-width="0"></g>
        <g
          id="SVGRepo_tracerCarrier"
          stroke-linecap="round"
          stroke-linejoin="round"
        ></g>
        <g id="SVGRepo_iconCarrier">
          <g>
            <g>
              <path
                d="m439.5,236c0-11.3-9.1-20.4-20.4-20.4s-20.4,9.1-20.4,20.4c0,70-64,126.9-142.7,126.9-78.7,0-142.7-56.9-142.7-126.9 0-11.3-9.1-20.4-20.4-20.4s-20.4,9.1-20.4,20.4c0,86.2 71.5,157.4 163.1,166.7v57.5h-23.6c-11.3,0-20.4,9.1-20.4,20.4 0,11.3 9.1,20.4 20.4,20.4h88c11.3,0 20.4-9.1 20.4-20.4 0-11.3-9.1-20.4-20.4-20.4h-23.6v-57.5c91.6-9.3 163.1-80.5 163.1-166.7z"
              ></path>
              <path
                d="m256,323.5c51,0 92.3-41.3 92.3-92.3v-127.9c0-51-41.3-92.3-92.3-92.3s-92.3,41.3-92.3,92.3v127.9c0,51 41.3,92.3 92.3,92.3zm-52.3-220.2c0-28.8 23.5-52.3 52.3-52.3s52.3,23.5 52.3,52.3v127.9c0,28.8-23.5,52.3-52.3,52.3s-52.3-23.5-52.3-52.3v-127.9z"
              ></path>
            </g>
          </g>
        </g>
      </svg> -->

      <div id="transcribedText"></div>
    </div>

    <script>
      const recognition = new (window.SpeechRecognition ||
        window.webkitSpeechRecognition)();
      recognition.lang = "en-US";
      recognition.interimResults = false;
      recognition.maxAlternatives = 1;

      recognition.onresult = function (event) {
        let transcript = event.results[0][0].transcript;
        console.log(transcript); // This can be removed later, it's just for debugging
        document.getElementById("transcribedText").textContent = transcript;
      };

      recognition.onerror = function (event) {
        console.error("Recognition error:", event.error);
      };

      let stream;
      let mediaRecorder;
      let audioChunks = [];

      function initiateRecording(str) {
        mediaRecorder = new MediaRecorder(str);
        mediaRecorder.ondataavailable = (event) => {
          audioChunks.push(event.data);
        };

        mediaRecorder.onstop = async () => {
          const audioBlob = new Blob(audioChunks, { type: "audio/wav" });
          audioChunks = [];
          const transcript = await sendToGCP(audioBlob);
          document.getElementById("transcribedText").textContent = transcript;
          str.getTracks().forEach((track) => track.stop());
        };

        mediaRecorder.start();
        document.getElementById("recordButton").textContent = "Stop Recording";
      }

      async function sendToGCP(blob) {
        const buffer = await blob.arrayBuffer();
        const audioBytes = Array.from(new Uint8Array(buffer))
          .map((byte) => {
            return ("0" + (byte & 0xff).toString(16)).slice(-2);
          })
          .join("");

        const audio = {
          content: audioBytes,
        };

        const request = {
          audio: audio,
          config: {
            encoding: "LINEAR16",
            sampleRateHertz: 16000,
            languageCode: "en-US",
            enableAutomaticPunctuation: true,
          },
        };

        const response = await fetch("/transcribe", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify(request),
        });

        const data = await response.json();
        return data.transcript;
      }

      window.onload = function () {
        const prompts = [
          "Talk about your favorite childhood memory.",
          "Describe the last movie you watched.",
          "What's your dream vacation destination?",
          "How do you feel about pineapples on pizza?",
          "Who is your role model and why?",
          "What book have you read recently?",
          "Tell about a unique talent you have.",
        ];

        const randomIndex = Math.floor(Math.random() * prompts.length);
        const selectedPrompt = prompts[randomIndex];
        document.getElementById("randomPrompt").textContent = selectedPrompt;

        document
          .getElementById("recordButton")
          .addEventListener("click", function () {
            if (
              typeof mediaRecorder === "undefined" ||
              mediaRecorder.state === "inactive"
            ) {
              if (!stream) {
                navigator.mediaDevices
                  .getUserMedia({ audio: true })
                  .then((str) => {
                    stream = str;
                    initiateRecording(stream);
                  })
                  .catch((error) => {
                    console.error("Error accessing the microphone.", error);
                  });
              } else {
                initiateRecording(stream);
              }
            } else if (mediaRecorder.state === "recording") {
              mediaRecorder.stop();
              recognition.stop();
              this.textContent = "Start Recording";
            }
          });
      };
    </script>
  </body>
</html>
